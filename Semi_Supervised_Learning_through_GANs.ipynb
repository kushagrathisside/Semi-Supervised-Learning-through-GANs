{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushagrathisside/Semi-Supervised-Learning-through-GANs/blob/main/Semi_Supervised_Learning_through_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's say that we are a Computer Vision Engineer working on a proof of concept for a mobile app that can identify melanomas among photos of melanocytic nevi (more commonly known simply as moles). Melanoma is the most dangerous type of skin cancer, and its early detection is the key factor in determining the chances of a patient’s long-term survival."
      ],
      "metadata": {
        "id": "_BBI2pnVL3fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our task is to construct a model to perform malignant vs. benign image classification on low-resolution photos typical of those taken with cellphone cameras. We will very soon see that our dataset has only 200 training images, 100 of which have been labeled as melanomas, and the other half as benign, whereas the number of unlabelled images will be much higher than that of training images. This much number of training images are specially very less for training such kind of models which should generalize well on unseen data.  "
      ],
      "metadata": {
        "id": "Bwnyft4zMQNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Furthermore, the scenario above is highly representative of the real life scenario regarding medical imaging data where unlabelled data in present in abundance but there is dearth of labelled data."
      ],
      "metadata": {
        "id": "TA5vD4wuOSFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So, now the challenge is to create such kind of a deep learning based model which will generalize well on unseen data and will be able to properly classify unlabelled data with good performance metrics, despite being trained on a very little training data."
      ],
      "metadata": {
        "id": "WRXe7RX9O9G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fortunately, there is an approach one can use to take advantage of unlabeled data, which is typically much cheaper to obtain and thus often available in large quantities. This approach is called semi-supervised learning. We will combine it with data augmentation techniques in order to build a classifier that will take in a 32x32 pixel photo of a melanocytic nevus, and output the probability of that image being melanoma-positive."
      ],
      "metadata": {
        "id": "Q2l4CFqpSZOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this approach of training a classifier in semi-supervised learning setup, we will be training a DCGAN (Deep Convolutional GAN) to generate mole-like images as well as using it as a classifier to get trained to classify labelled malignant as well as benign training images. This strategy will ensure that our trained model (Discriminator) will generalize very well on unseen images despite being trained on limited training data.  "
      ],
      "metadata": {
        "id": "OoKdABhZVHLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **About GANs**\n",
        "\n",
        "### Generative Adversarial Networks (GANs) are a class of machine learning techniques that consist of two simultaneously trained models: one (the Generator) trained to generate fake data, and the other (the Discriminator) trained to discern the fake data from real examples.\n"
      ],
      "metadata": {
        "id": "T4AL-buhE7wO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What does it mean by 'Generative'?**\n",
        "### The word generative indicates the overall purpose of the model: creating new data.The data that a GAN will learn to generate depends on the choice of the training set. For example, if we want a GAN to synthesize images that look like Leonardo da Vinci’s, we would use a training dataset of da Vinci’s artwork."
      ],
      "metadata": {
        "id": "iynT9Q2uFarO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The meaning of Adversarial**\n",
        "\n",
        "### The term adversarial points to the game-like, competitive dynamic between the two models that constitute the GAN framework: the Generator and the Discriminator. The Generator’s goal is to create examples that are indistinguishable from the real data in the training set. In our example, this means producing paintings that look just like da Vinci’s. The Discriminator’s objective is to distinguish the fake examples produced by the Generator from the real examples coming from the training dataset. In our example, the Discriminator plays the role of an art expert assessing the authenticity of paintings believed to be da Vinci’s. The two networks are continually trying to outwit each other: the better the Generator gets at creating convincing data, the better the Discriminator needs to be at distinguishing real examples from the fake ones."
      ],
      "metadata": {
        "id": "cYFb3FQ5F4mX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finally, the word networks indicates the class of machine learning models most commonly used to represent the Generator and the Discriminator: **neural networks**. Depending on the complexity of the GAN implementation, these can range from simple feed-forward neural networks to convolutional neural networks or even more complex variants, such as the U-Net.\n",
        "  "
      ],
      "metadata": {
        "id": "Ha0IA0g1GLwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  A metaphor often used to describe GANs—one that Ian Goodfellow himself likes to use—is that of a **criminal (the Generator)** who forges money, and a **detective (the Discriminator)** who tries to catch him. The more authentic-looking the counterfeit bills become, the better the detective must be at detecting them, and vice versa."
      ],
      "metadata": {
        "id": "Mq6AACrfG2Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In more technical terms, the Generator’s goal is to produce examples that capture the characteristics of the training dataset, so much so that the samples it generates look indistinguishable from the training data. The Generator can be thought of as an object recognition model in reverse. Object recognition algorithms learn the patterns in images to discern an image’s content. Instead of recognizing the patterns, **the Generator learns to create them essentially from scratch; indeed, the input into the Generator is often no more than a vector of random numbers.**"
      ],
      "metadata": {
        "id": "czl8XiMzH7Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How Generator of the GAN learns?**\n",
        "\n",
        "### The Generator learns through the feedback it receives from the Discriminator’s classifications. The Discriminator’s goal is to determine whether a particular example is real (coming from the training dataset) or fake (created by the Generator). Accordingly, each time the Discriminator is fooled into classifying a fake image as real, the Generator knows it did something well. Conversely, each time the Discriminator correctly rejects a Generator-produced image as fake, the Generator receives the feedback that it needs to improve."
      ],
      "metadata": {
        "id": "-gQDEm8wI1zR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How Discriminator of the GAN learns?**\n",
        "\n",
        "### The Discriminator continues to improve as well. Like any classifier, it learns from how far its predictions are from the true labels (real or fake). So, as the Generator gets better at producing realistic-looking data, the Discriminator gets better at telling fake data from the real, and both networks continue to improve simultaneously."
      ],
      "metadata": {
        "id": "lgRPPIR0JH8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![GAN Training Procedure](https://drive.google.com/uc?id=1sX1a3OR5N9u5Aw8usxpsTK-rc2Voinx-)"
      ],
      "metadata": {
        "id": "qUekAe0MLmZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finer details of GAN training**\n",
        "\n",
        "![Finer details of GAN training](https://drive.google.com/uc?id=1QhU3AOOvytdoBzR1Buv2Ql03Ru_vP-z6)\n",
        "![Finer details of GAN training Part 2](https://drive.google.com/uc?id=1jxKjB58pYI4KoqrPIxKXUeFQFBj6ET2u)"
      ],
      "metadata": {
        "id": "wiF-cvHVNNhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A DCGAN is a special kind of GAN where both Generator as well as Discriminator are Convolutional Networks, with Generator being a Fully Convolutional. Let's have a look on structure of Generator as well as Discriminator, seperately:"
      ],
      "metadata": {
        "id": "sIdo5umFQVqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Structure of a Generator**\n",
        "\n",
        "![Structure of a Generator](https://drive.google.com/uc?id=1KEdwGrWjZbEzZ1bR6q-gvst_JnYOwX_n)"
      ],
      "metadata": {
        "id": "zszz5NkrRZ4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Fully Convolutional Generator takes in a Random Noise Vector as Input and produces a fixed size Image whose size is same as that of Images in the training data (in this case, it is 28x28x1). It does so by multiple layers of transposed convolutions."
      ],
      "metadata": {
        "id": "4eEG7PBtScVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Structure of Discriminator**\n",
        "\n",
        "![Structure of Discriminator](https://drive.google.com/uc?id=1qhIL6TwrMcugkNSY4DbIAtTGgNLT9VaG)"
      ],
      "metadata": {
        "id": "-ph4KWKSTNmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Discriminator is usually a CNN architecture based Binary Classifier which takes in a fixed size image as an Input (in this example, it is 28x28x1), applies several convolutional layers and using the sigmoid activation function, outputs a probability that the Input image is real rather than fake (or the other way around)."
      ],
      "metadata": {
        "id": "37aYd8n_T5ln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Semi-Supervised GANs**"
      ],
      "metadata": {
        "id": "VodGD3TlWS23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semi-Supervised GAN (SGAN) is a Generative Adversarial Network whose Discriminator is a multiclass classifier. Instead of distinguishing between only two classes (real and fake), it learns to distinguish between N + 1 classes, where N is the number of classes in the training dataset, with one added for the fake examples produced by the Generator."
      ],
      "metadata": {
        "id": "SzzRNvQfYSbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In SGAN, we care primarily about the Discriminator. The goal of the training process is to make this network into a semi-supervised classifier whose accuracy is as close as possible to a fully supervised classifier (one that has labels available for each example in the training dataset), while using only a small fraction of the labels. The Generator’s goal is to aid this process by serving as a source of additional information (the fake data it produces) that helps the Generator learn the relevant patterns in the data, enhancing its classification accuracy. At the end of the training, the Generator gets discarded, and we use the trained Discriminator as a classifier."
      ],
      "metadata": {
        "id": "eWZWm_tzZFlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Overview of SGAN Training**\n",
        "\n",
        "![Overview of SGAN Training](https://drive.google.com/uc?id=1HHIsJqA2nj4g227pzNLVod9qrql_QwBF)"
      ],
      "metadata": {
        "id": "-6OOlZpoapb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As we can observe above that there are two heads of the Discriminator above, one is the Softmax Layer, through which it is able to classify between different classes of images present in the training data (in our case right now, these are MNIST handwritten digits) and other is the Sigmoid Layer through which it is able to classify between real and fake real looking images generated by the Generator.  "
      ],
      "metadata": {
        "id": "k3cV7Z7Ua8Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SGAN training Algorithm in a nutshell**\n",
        "\n",
        "### **For** each training iteration **do**\n",
        "\n",
        "1.   **Train the Discriminator (With only the Softmax Layer)**\n",
        "\n",
        "*   Take a random mini-batch of labeled real examples (x, y).\n",
        "*   Compute D((x, y)) for the given mini-batch and backpropagate the multiclass\n",
        "classification loss to update $\\theta^{(D)}$ to minimize the loss.\n",
        "\n",
        "2.   **Train the Discriminator (With Only the Sigmoid Layer)**\n",
        "\n",
        "*   Take a random mini-batch of unlabeled real examples x.\n",
        "*   Compute D(x) for the given mini-batch and backpropagate the binary classification\n",
        "loss to update $\\theta^{(D)}$ to minimize the loss.\n",
        "*   Take a mini-batch of random noise vectors z and generate a mini-batch of\n",
        "fake examples: G(z) = x*.\n",
        "*   Compute D(x*) for the given mini-batch and backpropagate the binary\n",
        "classification loss to update $\\theta^{(D)}$ to minimize the loss.\n",
        "\n",
        "3.   **Train the Generator**\n",
        "\n",
        "*    Take a mini-batch of random noise vectors z and generate a mini-batch of\n",
        "fake examples: G(z) = x*.\n",
        "*    Compute D(x*) for the given mini-batch and backpropagate the binary\n",
        "classification loss to update $\\theta^{(G)}$ to maximize the loss.\n",
        "\n",
        "### **End For**\n",
        "\n"
      ],
      "metadata": {
        "id": "3jXBl8GRb_zo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In order to simulate the scenario of having Unlabelled data in abundance and labelled data in dearth, we have taken a subset of data from the [The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T) where we have only 800 Images of Skin Lesions which are labelled as Benign or Malignant and around 7000 Images of Skin Lesions which are unlabelled and here is the [URL](https://lp-prod-resources.s3.amazonaws.com/278/45149/2021-02-19-19-47-43/MelanomaDetection.zip) of the dataset on which we will be training our SGAN.  "
      ],
      "metadata": {
        "id": "pF36Kkbhgu4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To make the scenario more realistic, out of these 800 Labelled Images, only 200 will be available for training SGAN and the rest of the 600 labelled images will be used as Testing or Cross Validation Images, to evaluate the performance of our finally trained classifier which will be our Discriminator."
      ],
      "metadata": {
        "id": "NESPDTPoisDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So, first we will download the dataset from the URL above into our Linux Instance Drive and then unzip it. After Unzipping, we will find three directories named: ```Train```, ```Test``` and ```Unlabelled```. For our training purposes, we will be using only two directories right now: ```Train``` as well as ```Unlabelled```. ```Train``` directory has 200 labelled training images, out of which 100 are labelled as Benign (Class 0) and rest of them are labelled as Malignant (Class 1), whereas the ```Unlabelled``` directory has only random images of Skin Lesions without any labels."
      ],
      "metadata": {
        "id": "g3McI1iuj-F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So, first of all, we will be creating two Python Image data ```generators```. The first one will be responsible to ```yeild``` mini batches having size as ```mb_size_labelled``` of labelled images from the ```Train``` directory.\n",
        "\n",
        "### On the other hand, the second one will be responsible to ```yield``` mini batches having size as ```mb_size_unlabelled``` of unlabelled random images from ```Unlabelled``` directory."
      ],
      "metadata": {
        "id": "ca0fWR0Ck9eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### These both ```generators``` can be easily created with the help of example provided [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"
      ],
      "metadata": {
        "id": "6aCRqW3wlmW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finally, now we can create an SGAN model, train and test it using ```keras``` library with the help of an exmaple provided [here](https://machinelearningmastery.com/semi-supervised-generative-adversarial-network/)"
      ],
      "metadata": {
        "id": "8dfKsXdnl37f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OqIEIgRKQvWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}